generation:
  llm_model: gemma3
  temperature: 0.2
  max_output_tokens: 512
  # Strategy threshold for deciding between Stuff vs Map-Reduce
  stuff_context_token_limit: 2000
  max_context_documents: 8


